<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Awesome Neural Codec Models | Qiang Li </title> <meta name="author" content="Qiang Li"> <meta name="description" content="a paper of list about netural codec model"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon_image.jpeg?00bed9b15708991c9865ce08ec4e7f96"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lqnoob.github.io/blog/2024/netural-codec/"> <script src="/assets/js/theme.js?aa53b3cfcb032d70e53ec046871e2530"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Qiang</span> Li </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Awesome Neural Codec Models</h1> <p class="post-meta"> Created in December 27, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/formatting"> <i class="fa-solid fa-hashtag fa-sm"></i> formatting</a>   <a href="/blog/tag/speech"> <i class="fa-solid fa-hashtag fa-sm"></i> speech</a>   <a href="/blog/tag/codec"> <i class="fa-solid fa-hashtag fa-sm"></i> codec</a>   ·   <a href="/blog/category/speech-language-model"> <i class="fa-solid fa-tag fa-sm"></i> speech-language-model</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <ul> <li> <table> <tbody> <tr> <td>[2024/12] <strong>FreeCodec: A disentangled neural speech codec with fewer tokens</strong> [<a href="https://arxiv.org/abs/2412.01053" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/exercise-book-yq/FreeCodec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://exercise-book-yq.github.io/FreeCodec-Demo/" rel="external nofollow noopener" target="_blank">demo</a>] <code class="language-plaintext highlighter-rouge">Code Comming Soon</code> </td> <td><em>speaker encoder, content encoder and prosody encoder</em></td> </tr> </tbody> </table> </li> <li>[2024/11] <strong>TS3-Codec: Transformer-Based Simple Streaming Single Codec</strong> [<a href="https://arxiv.org/abs/2411.18803" rel="external nofollow noopener" target="_blank">paper</a>] <em>free-convolution</em> </li> <li> <table> <tbody> <tr> <td>[2024/11] <strong>Scaling Transformer for Low-bitrate High-Quality Speech Coding</strong> [<a href="https://arxiv.org/abs/2411.19842" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/Stability-AI/stable-codec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://stability-ai.github.io/stable-codec-demo/" rel="external nofollow noopener" target="_blank">demo</a>] <code class="language-plaintext highlighter-rouge">Code Comming Soon</code> </td> <td><em>transformer-based and scale it into 1B parameter range</em></td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>[2024/11] <strong>PyramidCodec: Hierarchical Codec for Long-form Music Generation in Audio Domain</strong> [<a href="https://aclanthology.org/2024.findings-emnlp.246/" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://pyramidcodec.github.io/" rel="external nofollow noopener" target="_blank">demo</a>] <code class="language-plaintext highlighter-rouge">Code Comming Soon</code> </td> <td><em>Music Tokenizer, Similar to MsCodec</em></td> </tr> </tbody> </table> </li> <li>[2024/11] <strong>Wavehax: Aliasing-Free Neural Waveform Synthesis Based on 2D Convolution and Harmonic Prior for Reliable Complex Spectrogram Estimation</strong> [<a href="https://arxiv.org/abs/2411.06807" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/chomeyama/wavehax" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://chomeyama.github.io/wavehax-demo/" rel="external nofollow noopener" target="_blank">demo</a>] <em>aliasing-free</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/11] <strong>VChangeCodec: A High-efficiency Neural Speech Codec with Built-in Voice Changer for Real-time Communication</strong> [<a href="https://openreview.net/forum?id=qDSfOQBrOD" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://anonymous666-speech.github.io/Demo-VChangeCodec/" rel="external nofollow noopener" target="_blank">demo</a>] <em>integrates the Voice Changer model directly into the speech Codec</em> </li> <li> <table> <tbody> <tr> <td>[2024/11] <strong>Towards Codec-LM Co-design for Neural Codec Language Models</strong> [<a href="https://openreview.net/forum?id=KCVv3tICvp" rel="external nofollow noopener" target="_blank">paper</a>] <code class="language-plaintext highlighter-rouge">Code Comming Soon</code> </td> <td><em>proposing several codec-LM co-design strategies</em></td> </tr> </tbody> </table> </li> <li>[2024/11] <strong>hertz-dev</strong> [<a href="https://github.com/Standard-Intelligence/hertz-dev" rel="external nofollow noopener" target="_blank">code</a>] <em>WaveCodec</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/11] <strong>SimVQ: Addressing Representation Collapse in Vector Quantized Models with One Linear Layer</strong> [<a href="https://arxiv.org/abs/2411.02038" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/youngsheen/SimVQ" rel="external nofollow noopener" target="_blank">code</a>] <em>codebook collapse</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/11] <strong>MDCTCodec: A Lightweight MDCT-based Neural Audio Codec towards High Sampling Rate and Low Bitrate Scenarios</strong> [<a href="https://arxiv.org/abs/2411.00464" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://pb20000090.github.io/MDCTCodecSLT2024/" rel="external nofollow noopener" target="_blank">demo</a>] <em>discrete cosine transform (MDCT) as input</em> </li> <li>[2024/10] <strong>Pushing the frontiers of audio generation</strong> [<a href="https://deepmind.google/discover/blog/pushing-the-frontiers-of-audio-generation/" rel="external nofollow noopener" target="_blank">blog</a>] <em>google deepmind</em> </li> <li>[2024/11] <strong>DC-Spin: A Speaker-invariant Speech Tokenizer for Spoken Language Models</strong> [<a href="https://arxiv.org/abs/2410.24177" rel="external nofollow noopener" target="_blank">paper</a>] <em>Double-Codebook Speaker-invariant Clustering</em> </li> <li>[2024/10] <strong>A Closer Look at Neural Codec Resynthesis: Bridging the Gap between Codec and Waveform Generation</strong> [<a href="https://arxiv.org/abs/2410.22448" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://alexander-h-liu.github.io/codec-resyn.github.io/" rel="external nofollow noopener" target="_blank">demo</a>] <em>Is predicting the remaining RVQ codes necessary?</em> </li> <li>[2024/10] <strong>APCodec+: A Spectrum-Coding-Based High-Fidelity and High-Compression-Rate Neural Audio Codec with Staged Training Paradigm</strong> [<a href="https://arxiv.org/abs/2410.22807" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://redmist328.github.io/APCodecPlus-demo/" rel="external nofollow noopener" target="_blank">demo</a>] <em>two-stage joint-individual training paradigm</em> </li> <li>[2024/10] <strong>Optimizing Neural Speech Codec for Low-Bitrate Compression via Multi-Scale Encoding</strong> [<a href="https://arxiv.org/abs/2410.15749" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://tencentgamemate.github.io/MsCodec-Demo/" rel="external nofollow noopener" target="_blank">demo</a>] <em>MsCodec, Multi-Scale Encoding</em> </li> <li>[2024/10] <strong>LSCodec: Low-Bandwidth and Speaker-Decoupled Discrete Speech Codec</strong> [<a href="https://arxiv.org/abs/2410.15764" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://cantabile-kwok.github.io/LSCodec/" rel="external nofollow noopener" target="_blank">demo</a>] <em>speaker timbre decouple</em> </li> <li>[2024/10] <strong>DM-Codec: Distilling Multimodal Representations for Speech Tokenization</strong> [<a href="https://arxiv.org/abs/2410.15017" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/mubtasimahasan/DM-Codec" rel="external nofollow noopener" target="_blank">code</a>] <em>acoustic properties, semantic meaning, and contextual clues</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/10] <strong>ERVQ: Enhanced Residual Vector Quantization with Intra-and-Inter-Codebook Optimization for Neural Audio Codecs</strong> [<a href="https://arxiv.org/abs/2410.12359" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://anonymous.4open.science/w/ERVQ-A907/" rel="external nofollow noopener" target="_blank">demo</a>] <em>address codebook collapse based on intra- and inter-codebook optimization</em> </li> <li>[2024/10] <strong>Code Drift: Towards Idempotent Neural Audio Codecs</strong> [<a href="https://arxiv.org/abs/2410.11025" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://oreillyp.github.io/codedrift/" rel="external nofollow noopener" target="_blank">demo</a>] <em>Idempotence – the stability of a codec’s decoded output under multiple rounds of encoding and decoding</em> </li> <li>[2021/10] <strong>WavLM: Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing</strong> [<a href="https://arxiv.org/abs/2110.13900" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/microsoft/unilm/tree/master/wavlm" rel="external nofollow noopener" target="_blank">code</a>] <em>semantic information &amp; content generation</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2021/08] <strong>W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training</strong> [<a href="https://arxiv.org/abs/2108.06209" rel="external nofollow noopener" target="_blank">paper</a>]</li> <li>[2021/06] <strong>HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units</strong> [<a href="https://arxiv.org/abs/2106.07447" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/facebookresearch/fairseq/tree/main/examples/hubert" rel="external nofollow noopener" target="_blank">code</a>] <em>semantic information &amp; content generation</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2020/06] <strong>wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations</strong> [<a href="https://arxiv.org/abs/2006.11477" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/facebookresearch/fairseq/tree/main/examples/wav2vec" rel="external nofollow noopener" target="_blank">code</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/10] <strong>Low Bitrate High-Quality RVQGAN-based Discrete Speech Tokenizer</strong> [<a href="https://arxiv.org/abs/2410.08325" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://huggingface.co/ibm/DAC.speech.v1.0" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://s3.us-south.objectstorage.softlayer.net/zk-wav-data/Webpages/SpeechDAC_IS2024/index.html" rel="external nofollow noopener" target="_blank">demo</a>] <em>finetuned-version of DAC</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/09] <strong>BigCodec: Pushing the Limits of Low-Bitrate Neural Speech Codec</strong> [<a href="https://arxiv.org/abs/2409.05377" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/Aria-K-Alethia/BigCodec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://aria-k-alethia.github.io/bigcodec-demo/" rel="external nofollow noopener" target="_blank">demo</a>] <em>low-bitrate neural speech codec</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/10] <strong>Analyzing and Mitigating Inconsistency in Discrete Audio Tokens for Neural Codec Language Models</strong> [<a href="https://arxiv.org/abs/2409.19283" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://consistencyinneuralcodec.github.io/" rel="external nofollow noopener" target="_blank">demo</a>] <em>Inconsistency</em> </li> <li>[2024/09] <strong>Reverse Engineering of Supervised Semantic Speech Tokenizer (S3Tokenizer) proposed in CosyVoice</strong> [<a href="https://github.com/xingchensong/S3Tokenizer" rel="external nofollow noopener" target="_blank">code</a>] <em>S3Tokenizer</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/09] <strong>FlowMAC: Conditional Flow Matching for Audio Coding at Low Bit Rates</strong> [<a href="https://arxiv.org/abs/2409.17635" rel="external nofollow noopener" target="_blank">paper</a>] <em>Flow Matching</em> </li> <li>[2024/09] <strong>ESPnet-Codec: Comprehensive Training and Evaluation of Neural Codecs for Audio, Music, and Speech</strong> [<a href="https://arxiv.org/abs/2409.15897" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/espnet/espnet/tree/master/egs2/TEMPLATE/codec1" rel="external nofollow noopener" target="_blank">code</a>] <em>Comprehensive Platform</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/09] <strong>MuCodec: Ultra Low-Bitrate Music Codec</strong> [<a href="https://arxiv.org/abs/2409.13216" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/xuyaoxun/MuCodec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://xuyaoxun.github.io/MuCodec_demo/" rel="external nofollow noopener" target="_blank">demo</a>] <em>Music Codec</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/09] <strong>Audio Codec Augmentation for Robust Collaborative Watermarking of Speech Synthesis</strong> [<a href="https://arxiv.org/abs/2409.13382" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/ljuvela/collaborative-watermarking-with-codecs" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://ljuvela.github.io/collaborative-watermarking-with-codecs-demo/" rel="external nofollow noopener" target="_blank">demo</a>] <em>Watermarking</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/09] <strong>NDVQ: Robust Neural Audio Codec with Normal Distribution-Based Vector Quantization</strong> [<a href="https://arxiv.org/abs/2409.12717" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/ZhikangNiu/NDVQ" rel="external nofollow noopener" target="_blank">code</a>] <code class="language-plaintext highlighter-rouge">Code Comming Soon</code> </li> <li>[2024/09] <strong>Speaking from Coarse to Fine: Improving Neural Codec Language Model via Multi-Scale Speech Coding and Generation</strong> [<a href="https://arxiv.org/abs/2409.11630v1" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://hhguo.github.io/DemoCoFiSpeech/" rel="external nofollow noopener" target="_blank">demo</a>] <em>CoFi-Speech</em> </li> <li>[2024/09] <strong>SoCodec: A Semantic-Ordered Multi-Stream Speech Codec for Efficient Language Model Based Text-to-Speech Synthesis</strong> [<a href="https://arxiv.org/abs/2409.00933" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/hhguo/SoCodec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://hhguo.github.io/DemoSoCodec/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/08] <strong>Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio Language Model</strong> [<a href="https://arxiv.org/abs/2408.17175" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/zhenye234/xcodec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://x-codec-audio.github.io/" rel="external nofollow noopener" target="_blank">demo</a>] <em>X-Codec</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/08] <strong>WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio Language Modeling</strong> [<a href="https://arxiv.org/abs/2408.16532" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/jishengpeng/WavTokenizer" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://wavtokenizer.github.io/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/08] <strong>Music2Latent: Consistency Autoencoders for Latent Audio Compression</strong> [<a href="https://www.arxiv.org/abs/2408.06500" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/SonyCSLParis/music2latent" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://sonycslparis.github.io/music2latent-companion/" rel="external nofollow noopener" target="_blank">demo</a>] <em>continuous latent space</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/08] <strong>SimpleSpeech 2: Towards Simple and Efficient Text-to-Speech with Flow-based Scalar Latent Transformer Diffusion Models</strong> [<a href="https://arxiv.org/abs/2408.13893" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://dongchaoyang.top/SimpleSpeech2_demo/" rel="external nofollow noopener" target="_blank">demo</a>]</li> <li> <table> <tbody> <tr> <td>[2024/06] <strong>SimpleSpeech: Towards Simple and Efficient Text-to-Speech with Scalar Latent Transformer Diffusion Models</strong> [<a href="https://arxiv.org/abs/2406.02328v2" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/yangdongchao/SimpleSpeech" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://simplespeech.github.io/simplespeechDemo/" rel="external nofollow noopener" target="_blank">demo</a>] <em>SQ-Codec</em> </td> <td><code class="language-plaintext highlighter-rouge">Code Comming Soon</code></td> </tr> </tbody> </table> </li> <li>[2024/02] <strong>Language-Codec: Reducing the Gaps Between Discrete Codec Representation and Speech Language Models</strong> [<a href="https://arxiv.org/abs/2402.12208" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/jishengpeng/Languagecodec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://languagecodec.github.io/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/04] <strong>ESC: Efficient Speech Coding with Cross-Scale Residual Vector Quantized Transformers</strong> [<a href="https://arxiv.org/abs/2404.19441" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/yzGuu830/efficient-speech-codec" rel="external nofollow noopener" target="_blank">code</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/07] <strong>SuperCodec: A Neural Speech Codec with Selective Back-Projection Network</strong> [<a href="https://arxiv.org/abs/2407.20530" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/exercise-book-yq/Supercodec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://exercise-book-yq.github.io/SuperCodec-Demo/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/07] <strong>dMel: Speech Tokenization made Simple</strong> [<a href="https://arxiv.org/abs/2407.15835" rel="external nofollow noopener" target="_blank">paper</a>] <code class="language-plaintext highlighter-rouge">Code Comming Soon</code> </li> <li>[2024/02] <strong>APCodec: A Neural Audio Codec with Parallel Amplitude and Phase Spectrum Encoding and Decoding</strong> [<a href="https://arxiv.org/abs/2402.10533" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/YangAi520/APCodec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://yangai520.github.io/APCodec/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/06] <strong>Single-Codec: Single-Codebook Speech Codec towards High-Performance Speech Generation</strong> [<a href="https://www.arxiv.org/abs/2406.07422" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://kkksuper.github.io/Single-Codec/" rel="external nofollow noopener" target="_blank">demo</a>]</li> <li>[2024/07] <strong>CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens</strong> [<a href="https://fun-audio-llm.github.io/pdf/CosyVoice_v1.pdf" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/FunAudioLLM/CosyVoice" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://fun-audio-llm.github.io/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2023/06] <strong>Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis</strong> [<a href="https://arxiv.org/abs/2306.00814" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/gemelo-ai/vocos" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://gemelo-ai.github.io/vocos/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/04] <strong>SNAC: Multi-Scale Neural Audio Codec</strong> [<a href="https://www.arxiv.org/abs/2410.14411" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/hubertsiuzdak/snac" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://hubertsiuzdak.github.io/snac/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/06] <strong>UniAudio 1.5: Large Language Model-driven Audio Codec is A Few-shot Audio Task Learner</strong> [<a href="https://arxiv.org/abs/2406.10056" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/yangdongchao/LLM-Codec" rel="external nofollow noopener" target="_blank">code</a>] <em>LLM-Codec</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/01] <strong>Finite Scalar Quantization: VQ-VAE Made Simple</strong> [<a href="https://openreview.net/forum?id=8ishA3LxN8" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/google-research/google-research/tree/master/fsq" rel="external nofollow noopener" target="_blank">code</a>] <em>FSQ, no codebook collapse</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/06] <strong>Spectral Codecs: Spectrogram-Based Audio Codecs for High Quality Speech Synthesis</strong> [<a href="https://arxiv.org/abs/2406.05298" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/NVIDIA/NeMo" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://rlangman.github.io/spectral-codec/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2023/09] <strong>Generative Pre-trained Speech Language Model with Efficient Hierarchical Transformer</strong> [<a href="https://openreview.net/forum?id=TJNCnkDRkY" rel="external nofollow noopener" target="_blank">paper</a>]</li> <li>[2024/06] <strong>BiVocoder: A Bidirectional Neural Vocoder Integrating Feature Extraction and Waveform Generation</strong> [<a href="https://arxiv.org/abs/2406.02162" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://redmist328.github.io/BiVcoder_demo" rel="external nofollow noopener" target="_blank">demo</a>]</li> <li>[2024/04] <strong>The X-LANCE Technical Report for Interspeech 2024 Speech Processing Using Discrete Speech Unit Challenge</strong> [<a href="https://arxiv.org/abs/2404.06079v2" rel="external nofollow noopener" target="_blank">paper</a>]</li> <li> <table> <tbody> <tr> <td>[2023/06] <strong>UniCATS: A Unified Context-Aware Text-to-Speech Framework with Contextual VQ-Diffusion and Vocoding</strong> [<a href="https://arxiv.org/abs/2306.07547v6" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/X-LANCE/UniCATS-CTX-vec2wav" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://cpdu.github.io/unicats/" rel="external nofollow noopener" target="_blank">demo</a>] *acoustic model CTX-txt2vec and vocoder CTX-vec2wav</td> <td>speech continuation and editing</td> <td>similar to Encoder-Decoder* <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </td> </tr> </tbody> </table> </li> <li>[2024/06] <strong>Addressing Index Collapse of Large-Codebook Speech Tokenizer with Dual-Decoding Product-Quantized Variational Auto-Encoder</strong> [<a href="https://arxiv.org/abs/2406.02940" rel="external nofollow noopener" target="_blank">paper</a>]</li> <li>[2024/06] <strong>Coding Speech through Vocal Tract Kinematics</strong> [<a href="https://arxiv.org/abs/2406.12998" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/Berkeley-Speech-Group/Speech-Articulatory-Coding" rel="external nofollow noopener" target="_blank">code</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/05] <strong>HILCodec: High Fidelity and Lightweight Neural Audio Codec</strong> [<a href="https://arxiv.org/abs/2405.04752" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/aask1357/hilcodec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://aask1357.github.io/hilcodec/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/04] <strong>SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound</strong> [<a href="https://arxiv.org/abs/2405.00233" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/haoheliu/SemantiCodec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://haoheliu.github.io/SemantiCodec/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/01] <strong>Residual Quantization with Implicit Neural Codebooks</strong> [<a href="https://arxiv.org/abs/2401.14732" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/facebookresearch/Qinco" rel="external nofollow noopener" target="_blank">code</a>] <em>Qinco</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/01] <strong>SpeechTokenizer: Unified Speech Tokenizer for Speech Language Models</strong> [<a href="https://openreview.net/forum?id=AF9Q8Vip84" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/ZhangXInFD/SpeechTokenizer" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://0nutation.github.io/SpeechTokenizer.github.io/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2024/01] <strong>Residual Quantization with Implicit Neural Codebooks</strong> [<a href="https://arxiv.org/abs/2401.14732" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/facebookresearch/Qinco" rel="external nofollow noopener" target="_blank">code</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2023/10] <strong>Acoustic BPE for Speech Generation with Discrete Tokens</strong> [<a href="https://arxiv.org/abs/2310.14580" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/AbrahamSanders/codec-bpe" rel="external nofollow noopener" target="_blank">code</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2023/09] <strong>BANC: Towards Efficient Binaural Audio Neural Codec for Overlapping Speech</strong> [<a href="https://arxiv.org/abs/2309.07416" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/anton-jeran/MULTI-AUDIODEC" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://anton-jeran.github.io/MAD/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2023/09] <strong>Fewer-token Neural Speech Codec with Time-invariant Codes</strong> [<a href="https://arxiv.org/abs/2310.00014" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/y-ren16/TiCodec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://y-ren16.github.io/TiCodec/" rel="external nofollow noopener" target="_blank">demo</a>] <em>Ti-Codec</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2023/09] <strong>FunCodec: A Fundamental, Reproducible and Integrable Open-source Toolkit for Neural Speech Codec</strong> [<a href="https://arxiv.org/abs/2309.07405v2" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/modelscope/FunCodec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://funcodec.github.io/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2023/09] <strong>High Fidelity Neural Audio Compression</strong> [<a href="https://openreview.net/forum?id=ivCd8z8zR2" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/facebookresearch/encodec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://github.com/ZhikangNiu/encodec-pytorch" rel="external nofollow noopener" target="_blank">code-Unofficial</a>] [<a href="https://ai.honu.io/papers/encodec/samples.html" rel="external nofollow noopener" target="_blank">demo</a>] <em>Encodec</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2023/09] <strong>Soundstorm: Efficient parallel audio generation</strong> [<a href="https://openreview.net/forum?id=KknWbD5j95" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://google-research.github.io/seanet/soundstorm/examples/" rel="external nofollow noopener" target="_blank">demo</a>]</li> <li>[2023/09] <strong>High-Fidelity Audio Compression with Improved RVQGAN</strong> [<a href="https://openreview.net/forum?id=qjnl1QUnFA" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/descriptinc/descript-audio-codec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://descript.notion.site/Descript-Audio-Codec-11389fce0ce2419891d6591a68f814d5" rel="external nofollow noopener" target="_blank">demo</a>] <em>DAC</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2023/09] <strong>SpatialCodec: Neural Spatial Speech Coding</strong> [<a href="https://arxiv.org/abs/2309.07432" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/XZWY/SpatialCodec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://xzwy.github.io/SpatialCodecDemo/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2023/05] <strong>HiFi-Codec: Group-residual Vector quantization for High Fidelity Audio Codec</strong> [<a href="https://arxiv.org/abs/2305.02765v2" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/yangdongchao/AcademiCodec" rel="external nofollow noopener" target="_blank">code</a>] <em>AcademiCodec &amp; Group-RVQ</em> <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2023/05] <strong>AudioDec: An Open-source Streaming High-fidelity Neural Audio Codec</strong> [<a href="https://arxiv.org/abs/2305.16608" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/facebookresearch/AudioDec" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://bigpon.github.io/AudioDec_demo/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2023/01] <strong>InstructTTS: Modelling Expressive TTS in Discrete Latent Space with Natural Language Style Prompt</strong> [<a href="https://arxiv.org/abs/2301.13662v2" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/yangdongchao/InstructTTS" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://dongchaoyang.top/InstructTTS/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> <li>[2022/09] <strong>AudioLM: a Language Modeling Approach to Audio Generation</strong> [<a href="https://arxiv.org/abs/2209.03143v2" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://google-research.github.io/seanet/audiolm/examples/" rel="external nofollow noopener" target="_blank">demo</a>]</li> <li>[2021/07] <strong>SoundStream: An End-to-End Neural Audio Codec</strong> [<a href="https://arxiv.org/abs/2107.03312" rel="external nofollow noopener" target="_blank">paper</a>][<a href="https://github.com/google/lyra" rel="external nofollow noopener" target="_blank">code</a>][<a href="https://google-research.github.io/seanet/soundstream/examples/" rel="external nofollow noopener" target="_blank">demo</a>] <img class="emoji" title=":heavy_check_mark:" alt=":heavy_check_mark:" src="https://github.githubassets.com/images/icons/emoji/unicode/2714.png" height="20" width="20"> </li> </ul> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Qiang Li. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: January 02, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>